# =============================================================================
# HIB.RÄ°T Ã‡Ã–ZÃœM: CORD + SENTETÄ°K + OCR GÃœRÃœLTÃœSÃœ (AUGMENTATION)
# =============================================================================

import json
import re
import random
import datetime
from datasets import load_dataset, Dataset

print("ğŸš€ Veri hazÄ±rlama iÅŸlemi baÅŸlÄ±yor...")

# ==========================================
# 1. OCR GÃœRÃœLTÃœSÃœ ENJEKSÄ°YONU (Augmentation)
# ==========================================
def inject_ocr_noise(text, probability=0.1):
    """
    GerÃ§ek dÃ¼nyadaki OCR hatalarÄ±nÄ± simÃ¼le eder.
    Metindeki karakterleri %10 ihtimalle benzer ama yanlÄ±ÅŸ karakterlerle deÄŸiÅŸtirir.
    """
    noise_map = {
        'S': '5', '5': 'S',
        'I': '1', '1': 'I', 'l': '1',
        'O': '0', '0': 'O',
        'B': '8', '8': 'B',
        'Z': '2', '2': 'Z',
        'A': '4',
        'E': 'F',
        ':': '.', '.': ',',
        ' ': '  ' # Ã‡ift boÅŸluk
    }
    
    chars = list(text)
    for i, char in enumerate(chars):
        if random.random() < probability:
            # 1. Karakter deÄŸiÅŸimi
            if char in noise_map:
                chars[i] = noise_map[char]
            # 2. Rastgele bozulma
            elif random.random() < 0.2:
                chars[i] = random.choice(['.', '-', '*', '_', ' '])
                
    return "".join(chars)

# ==========================================
# 2. SENTETÄ°K TÃœRKÃ‡E VERÄ° ÃœRETÄ°CÄ°
# ==========================================
def generate_synthetic_turkish_data(count=2000):
    print(f"ğŸ‡¹ğŸ‡· {count} adet Sentetik TÃ¼rkÃ§e FiÅŸ Ã¼retiliyor...")
    
    MARKETS = ["BIM", "A101", "MIGROS", "SOK", "TEKEL SHOP", "FIRIN", "KASAP", "ECZANE"]
    PRODUCTS = [
        {"name": "SUT", "price": (20, 35)},
        {"name": "EKMEK", "price": (10, 15)},
        {"name": "YUMURTA", "price": (80, 120)},
        {"name": "PEYNIR", "price": (150, 250)},
        {"name": "ZEYTIN", "price": (200, 300)},
        {"name": "KOLA", "price": (30, 50)},
        {"name": "CIPS", "price": (25, 45)},
        {"name": "DETERJAN", "price": (100, 200)},
    ]
    
    data = []
    for _ in range(count):
        market = random.choice(MARKETS)
        date_obj = datetime.date(2023, 1, 1) + datetime.timedelta(days=random.randint(0, 365))
        date_str = date_obj.strftime('%d.%m.%Y')
        
        item_count = random.randint(2, 6)
        total = 0
        lines = [f"*** {market} ***", f"Tarih: {date_str}"]
        
        for _ in range(item_count):
            prod = random.choice(PRODUCTS)
            price = round(random.uniform(*prod['price']), 2)
            qty = random.randint(1, 3)
            line_total = price * qty
            total += line_total
            lines.append(f"{prod['name']} x{qty} {line_total:.2f}")
            
        tax = total * 0.18 # Basit KDV
        lines.append(f"TOPLAM: {total:.2f}")
        lines.append(f"KDV: {tax:.2f}")
        
        full_text = "\n".join(lines)
        
        # Hem temiz hem gÃ¼rÃ¼ltÃ¼lÃ¼ versiyonunu ekle
        gt = {"satici": market, "tarih": date_str, "toplam": f"{total:.2f}", "kdv": f"{tax:.2f}"}
        
        # 1. Temiz Veri
        data.append({"text": full_text, "gt": gt})
        # 2. GÃ¼rÃ¼ltÃ¼lÃ¼ Veri (Augmentation)
        data.append({"text": inject_ocr_noise(full_text, 0.15), "gt": gt})
        
    return data

# ==========================================
# 3. CORD VERÄ° SETÄ°NÄ° Ã‡EK VE Ä°ÅLE
# ==========================================
processed_data = []

try:
    print("ğŸŒ HuggingFace CORD verisi indiriliyor...")
    hf_dataset = load_dataset("naver-clova-ix/cord-v2", split="train")
    
    print(f"âœ… {len(hf_dataset)} adet CORD fiÅŸi iÅŸleniyor...")
    
    for item in hf_dataset:
        try:
            gt_json = json.loads(item.get('ground_truth', '{}'))
            
            # Text oluÅŸtur
            lines = []
            if "valid_line" in gt_json:
                for l in gt_json["valid_line"]:
                    words = l.get("words", [])
                    lines.append(" ".join([w["text"] for w in words]))
            full_text = "\n".join(lines)
            
            # DeÄŸerleri Ã§ek
            date_val = "BulunamadÄ±"
            total_val = "0.00"
            tax_val = "0.00"
            merchant_val = "Bilinmiyor"
            
            if "valid_line" in gt_json:
                for l in gt_json["valid_line"]:
                    cat = l.get("category", "")
                    txt = " ".join([w["text"] for w in l.get("words", [])])
                    if "menu.date" in cat: date_val = txt
                    elif "total.total_price" in cat: total_val = txt
                    elif "total.tax_price" in cat: tax_val = txt
                    elif "store.name" in cat: merchant_val = txt
            
            if total_val == "0.00": continue

            gt = {
                "satici": merchant_val,
                "tarih": date_val,
                "toplam": total_val,
                "kdv": tax_val
            }
            
            # CORD verisini 3 kez Ã§oÄŸalt (1 Temiz + 2 GÃ¼rÃ¼ltÃ¼lÃ¼)
            processed_data.append({"text": full_text, "gt": gt})
            processed_data.append({"text": inject_ocr_noise(full_text, 0.1), "gt": gt})
            processed_data.append({"text": inject_ocr_noise(full_text, 0.2), "gt": gt})
            
        except: continue
        
except Exception as e:
    print(f"âš ï¸ CORD hatasÄ± (Sentetik ile devam edilecek): {e}")

# ==========================================
# 4. SENTETÄ°K VERÄ° EKLE
# ==========================================
# 1000 kÃ¶k sentetik veri -> 2000 augment edilmiÅŸ veri olur
synthetic_samples = generate_synthetic_turkish_data(1000) 
processed_data.extend(synthetic_samples)

print(f"\nğŸ“Š TOPLAM EÄÄ°TÄ°M VERÄ°SÄ°: {len(processed_data)} adet")

# ==========================================
# 5. UNSLOTH FORMATINA DÃ–NÃœÅTÃœR VE KAYDET
# ==========================================
final_jsonl = []

prompt_template = """Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
Fatura metninden satÄ±cÄ± adÄ±, tarih, toplam tutar ve KDV bilgilerini JSON formatÄ±nda Ã§Ä±kar.

### Input:
{text}

### Response:
{response}""" + "<|end_of_text|>"

for item in processed_data:
    response_str = json.dumps(item['gt'], ensure_ascii=False)
    formatted_text = prompt_template.format(text=item['text'], response=response_str)
    final_jsonl.append({"text": formatted_text})

# KarÄ±ÅŸtÄ±r
random.shuffle(final_jsonl)

output_filename = "turkish_receipt_large_dataset.jsonl"
with open(output_filename, "w", encoding="utf-8") as f:
    for entry in final_jsonl:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")

print(f"ğŸ’¾ '{output_filename}' kaydedildi.")
print("âœ… Bu dosya ile Fine-Tuning iÅŸlemini baÅŸlatabilirsiniz.")
